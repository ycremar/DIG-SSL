{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example for reproducing GraphCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sslgraph.utils import Encoder, EvalSemisupevised, EvalUnsupevised, get_dataset\n",
    "from sslgraph.contrastive.model import GraphCL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Semi-supervised learning setting\n",
    "\n",
    "#### Load dataset\n",
    "\n",
    "In this example, we evaluate model on NCI1 dataset in the semi-supervised setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset, dataset_pretrain = get_dataset('NCI1', task='semisupervised')\n",
    "feat_dim = dataset[0].x.shape[1]\n",
    "n_class = dataset.num_classes\n",
    "embed_dim = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define your encoder and contrastive model (GraphCL)\n",
    "\n",
    "For semi-supervised setting, GraphCL uses ResGCN. \n",
    "\n",
    "Available augmentation includes: dropN, maskN, permE, subgraph, random[2-4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(feat_dim, embed_dim, n_layers=3, gnn='resgcn')\n",
    "graphcl = GraphCL(embed_dim, aug_1='dropN', aug_2='dropN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define evaluatior instance\n",
    "\n",
    "In this example, we use a label rate of 1%.\n",
    "\n",
    "To setup configurations (num of epochs, learning rates, etc. for pretraining and finetuning), run\n",
    "\n",
    "\n",
    "`evaluator.setup_train_config(batch_size = 128,\n",
    "    p_optim = 'Adam', p_lr = 0.0001, p_weight_decay = 0, p_epoch = 100,\n",
    "    f_optim = 'Adam', f_lr = 0.001, f_weight_decay = 0, f_epoch = 100)`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = EvalSemisupevised(dataset, dataset_pretrain, 0.01, n_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform evaluation\n",
    "\n",
    "You can also perform evaluation with grid search on pre-training epoch and\n",
    "learning rate by running\n",
    "``\n",
    "evaluator.grid_search(learning_model=graphcl, encoder=encoder, \n",
    "    p_lr_lst=[0.1,0.01,0.001,0.0001], p_epoch_lst=[20,40,60,80,100])\n",
    "``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining: epoch 100: 100%|██████████| 100/100 [09:03<00:00,  5.43s/it, loss=0.831101]\n",
      "Fold 1, finetuning: 100%|██████████| 100/100 [00:16<00:00,  6.23it/s, acc=0.5888, val_loss=2.5162]\n",
      "Fold 2, finetuning: 100%|██████████| 100/100 [00:14<00:00,  7.00it/s, acc=0.6399, val_loss=7.7734]\n",
      "Fold 3, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.41it/s, acc=0.5207, val_loss=3.1536]\n",
      "Fold 4, finetuning: 100%|██████████| 100/100 [00:16<00:00,  6.16it/s, acc=0.6131, val_loss=3.7445]\n",
      "Fold 5, finetuning: 100%|██████████| 100/100 [00:14<00:00,  7.00it/s, acc=0.5888, val_loss=2.7536]\n",
      "Fold 6, finetuning: 100%|██████████| 100/100 [00:16<00:00,  6.21it/s, acc=0.6229, val_loss=1.5371]\n",
      "Fold 7, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.29it/s, acc=0.6229, val_loss=1.9644]\n",
      "Fold 8, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.64it/s, acc=0.6302, val_loss=2.1328]\n",
      "Fold 9, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.25it/s, acc=0.6156, val_loss=2.0700]\n",
      "Fold 10, finetuning: 100%|██████████| 100/100 [00:16<00:00,  5.99it/s, acc=0.6229, val_loss=2.2339]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6282238960266113, 0.04049957916140556)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.evaluate(learning_model=graphcl, encoder=encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reproduce results in the paper, you may want to perform grid search and run evaluation for 5 times and take the average."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another example with a label rate of 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining: epoch 100: 100%|██████████| 100/100 [10:48<00:00,  6.49s/it, loss=2.119937]\n",
      "Fold 1, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.59it/s, acc=0.7859, val_loss=0.8773]\n",
      "Fold 2, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.57it/s, acc=0.7226, val_loss=1.5608]\n",
      "Fold 3, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.39it/s, acc=0.7348, val_loss=1.3909]\n",
      "Fold 4, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.44it/s, acc=0.7421, val_loss=1.4355]\n",
      "Fold 5, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.44it/s, acc=0.7372, val_loss=1.1765]\n",
      "Fold 6, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.43it/s, acc=0.7105, val_loss=1.4596]\n",
      "Fold 7, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.40it/s, acc=0.7056, val_loss=1.3956]\n",
      "Fold 8, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.40it/s, acc=0.6740, val_loss=1.4866]\n",
      "Fold 9, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.43it/s, acc=0.7397, val_loss=1.3395]\n",
      "Fold 10, finetuning: 100%|██████████| 100/100 [00:15<00:00,  6.34it/s, acc=0.7105, val_loss=1.5021]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.7408758401870728, 0.025447474792599678)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder = Encoder(feat_dim, embed_dim, n_layers=3, gnn='resgcn')\n",
    "graphcl = GraphCL(embed_dim, aug_1='subgraph', aug_2='random2')\n",
    "evaluator = EvalSemisupevised(dataset, dataset_pretrain, 0.1, n_class)\n",
    "evaluator.evaluate(learning_model=graphcl, encoder=encoder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Unsupervised learning setting\n",
    "\n",
    "#### Load dataset\n",
    "\n",
    "In this example, we evaluate model on MUTAG dataset in the unsupervised setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = get_dataset('MUTAG', task='unsupervised')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define your encoder and contrastive model (GraphCL)\n",
    "\n",
    "For unsupervised setting, GraphCL uses GIN with jumping knowledge (with output_dim = hidden_dim * n_layers). \n",
    "\n",
    "Available augmentation includes: dropN, maskN, permE, subgraph, random[2-4]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_dim = 128\n",
    "encoder = Encoder(feat_dim=dataset[0].x.shape[1], hidden_dim=embed_dim, n_layers=3, gnn='gin')\n",
    "graphcl = GraphCL(embed_dim*3, aug_1=None, aug_2='random2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Perform evaluation with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Pretraining: epoch 5: 100%|██████████| 5/5 [00:00<00:00,  6.69it/s, loss=5.231107]\n",
      "Pretraining: epoch 10: 100%|██████████| 10/10 [00:01<00:00,  5.92it/s, loss=5.231107]\n",
      "Pretraining: epoch 15: 100%|██████████| 15/15 [00:02<00:00,  6.58it/s, loss=5.222739]\n",
      "Pretraining: epoch 20: 100%|██████████| 20/20 [00:03<00:00,  6.66it/s, loss=5.231109]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best paras: 5 epoch, lr=0.010000, acc=0.8725\n"
     ]
    }
   ],
   "source": [
    "evaluator = EvalUnsupevised(dataset, dataset.num_classes)\n",
    "acc, sd, paras = evaluator.grid_search(learning_model=graphcl, encoder=encoder, \n",
    "                                       p_lr_lst=[0.01], p_epoch_lst=[5,10,15,20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
